# Autoencoders: A Jupyter Notebook Overview
This Jupyter notebook provides an overview of several different types of autoencoders, including linear autoencoders, convolutional autoencoders, Variational Autoencoders (VAEs), convolutional VAEs, and Vector Quantized VAEs (VQ-VAEs). Autoencoders are an important type of model in the field of deep learning, and they have many different applications in areas such as image compression, natural language processing, and more.


## Contents
The notebook is divided into several sections, each of which covers a different type of autoencoder:

Linear Autoencoder: An autoencoder that uses only linear layers to encode and decode data
Convolutional Autoencoder: An autoencoder that uses convolutional layers to encode and decode image data
Variational Autoencoder (VAE): An autoencoder that learns a distribution over the latent space, allowing for more diverse and realistic outputs.

paper: https://arxiv.org/pdf/1312.6114v10.pdf

Convolutional VAE: A VAE that uses convolutional layers to encode and decode image data
Vector Quantized VAE (VQ-VAE): A VAE that uses a vector quantization algorithm to discretize the latent space.

paper: https://arxiv.org/abs/1711.00937

Each section includes a brief overview of the type of autoencoder, as well as example code and visualizations to help illustrate how the model works.

### Contributing
If you find any errors or issues with this notebook, please feel free to create an issue or pull request on GitHub. You can also reach out to me directly if you have any questions or feedback.
